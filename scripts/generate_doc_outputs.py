#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
docflow - æ–‡ç¨¿è½‰æ›å·¥å…·

ä¾æ“š AI ç”¢ç”Ÿçš„ Markdownï¼Œè¼¸å‡ºï¼š
- è…³æœ¬_templete.docx / æ¡è¨ªç¨¿_templete.docx
- è…³æœ¬æ¬„ä½èªªæ˜.json / æ¡è¨ªç¨¿èªªæ˜.json
- è…³æœ¬.md / æ¡è¨ªç¨¿.mdï¼ˆè¤‡è£½ä¾†æºæˆ–è¦†å¯«ï¼‰

ä½¿ç”¨æ–¹å¼ï¼š
    python scripts/generate_doc_outputs.py --type è…³æœ¬ input_file.md
    python scripts/generate_doc_outputs.py --type æ¡è¨ªç¨¿ input_file.md
"""

import argparse
import json
import pathlib
import re
import subprocess
import sys
from typing import Dict, Any, List


def md_to_docx(md_path: pathlib.Path, docx_path: pathlib.Path, reference_docx: pathlib.Path = None) -> None:
    """ä½¿ç”¨ pandoc å°‡ Markdown è½‰ç‚º Word"""
    cmd = ["pandoc", str(md_path), "-o", str(docx_path)]

    # å¦‚æœæœ‰ reference.docxï¼Œä½¿ç”¨å®ƒä¾†å¥—ç”¨æ¨£å¼
    if reference_docx and reference_docx.exists():
        cmd.extend(["--reference-doc", str(reference_docx)])

    try:
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        print(f"âœ“ å·²è½‰æ›ç‚º Wordï¼š{docx_path}")
    except subprocess.CalledProcessError as e:
        print(f"âœ— pandoc è½‰æ›å¤±æ•—ï¼š{e.stderr}", file=sys.stderr)
        raise
    except FileNotFoundError:
        print("âœ— æ‰¾ä¸åˆ° pandocï¼Œè«‹å…ˆå®‰è£ pandoc", file=sys.stderr)
        print("  å®‰è£æ–¹å¼ï¼šhttps://pandoc.org/installing.html", file=sys.stderr)
        raise


def extract_yaml_frontmatter(md_text: str) -> Dict[str, Any]:
    """æå– YAML front matter"""
    frontmatter = {}

    # åŒ¹é… YAML front matter (åœ¨æ–‡ä»¶é–‹é ­çš„ --- åŒ…åœå€å¡Š)
    pattern = r'^---\s*\n(.*?)\n---\s*\n'
    match = re.search(pattern, md_text, re.DOTALL | re.MULTILINE)

    if match:
        yaml_content = match.group(1)
        # ç°¡å–®è§£æ YAML (åªè™•ç† key: value æ ¼å¼)
        for line in yaml_content.split('\n'):
            line = line.strip()
            if ':' in line:
                key, value = line.split(':', 1)
                key = key.strip()
                value = value.strip().strip('"').strip("'")
                frontmatter[key] = value

    return frontmatter


def extract_fields_from_md(md_text: str, doc_type: str) -> Dict[str, Any]:
    """
    å¾ Markdown æå–æ¬„ä½

    æå–é‚è¼¯ï¼š
    - ä¸»æ¨™ï¼šä¸€ç´šæ¨™é¡ŒåŒ…å«ã€Œä¸»æ¨™ã€
    - çœ‰æ¨™ï¼šä¸€ç´šæ¨™é¡ŒåŒ…å«ã€Œçœ‰æ¨™ã€æˆ–ã€Œåº§å³éŠ˜ã€
    - æ®µè½ï¼šä¸€ç´šæ¨™é¡ŒåŒ…å«ã€Œæ®µä¸€ã€ã€Œæ®µäºŒã€ç­‰
    - å—è¨ªè€…ç¶“æ­·ï¼šä¸€ç´šæ¨™é¡ŒåŒ…å«ã€Œç¶“æ­·ã€
    - æ‘˜è¦ï¼šä¸€ç´šæ¨™é¡ŒåŒ…å«ã€Œæ‘˜è¦ã€
    """
    fields: Dict[str, Any] = {}

    # æå– front matter
    frontmatter = extract_yaml_frontmatter(md_text)
    if frontmatter:
        fields["frontmatter"] = frontmatter

    # ä¸»æ¨™
    m_headline = re.search(r'^#\s+ä¸»æ¨™\s*\n+(.+?)(?=\n#|\Z)', md_text, re.MULTILINE | re.DOTALL)
    if m_headline:
        fields["headline"] = m_headline.group(1).strip()

    # çœ‰æ¨™æˆ–åº§å³éŠ˜
    m_subhead = re.search(r'^#\s+(çœ‰æ¨™|åº§å³éŠ˜|çœ‰æ¨™\(åº§å³éŠ˜\)|çœ‰æ¨™ï¼ˆåº§å³éŠ˜ï¼‰)\s*\n+(.+?)(?=\n#|\Z)',
                          md_text, re.MULTILINE | re.DOTALL)
    if m_subhead:
        fields["subhead"] = m_subhead.group(2).strip()

    # å—è¨ªè€…
    if "subject_person" in frontmatter:
        fields["subject_person"] = frontmatter["subject_person"]

    # å—è¨ªè€…ç¶“æ­·
    m_bio = re.search(r'^#\s+å—è¨ªè€…ç¶“æ­·\s*\n+(.+?)(?=\n#|\Z)', md_text, re.MULTILINE | re.DOTALL)
    if m_bio:
        fields["bio"] = m_bio.group(1).strip()

    # æ‘˜è¦
    m_summary = re.search(r'^#\s+æ‘˜è¦\s*\n+(.+?)(?=\n#|\Z)', md_text, re.MULTILINE | re.DOTALL)
    if m_summary:
        fields["summary"] = m_summary.group(1).strip()

    # æ®µè½æ¨™é¡Œï¼ˆæ®µä¸€ã€æ®µäºŒã€æ®µä¸‰ã€æ®µå››ç­‰ï¼‰
    sections: List[Dict[str, Any]] = []
    section_pattern = r'^#\s+(æ®µ[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)[\sã€€]+(.+?)$'

    for m in re.finditer(section_pattern, md_text, flags=re.MULTILINE):
        section_num = m.group(1)  # æ®µä¸€ã€æ®µäºŒç­‰
        section_title = m.group(2).strip()  # æ®µè½æ¨™é¡Œ

        # æå–è©²æ®µè½çš„å…§å®¹ï¼ˆå¾é€™å€‹æ¨™é¡Œåˆ°ä¸‹ä¸€å€‹ä¸€ç´šæ¨™é¡Œä¹‹å‰ï¼‰
        section_start = m.end()
        next_header = re.search(r'\n#\s+', md_text[section_start:])

        if next_header:
            section_end = section_start + next_header.start()
        else:
            section_end = len(md_text)

        section_content = md_text[section_start:section_end].strip()

        sections.append({
            "number": section_num,
            "title": section_title,
            "content": section_content[:200] + "..." if len(section_content) > 200 else section_content
        })

    if sections:
        fields["sections"] = sections

    # é‡å°è…³æœ¬é¡å‹ï¼Œé¡å¤–æå–æ ¸å¿ƒè¨Šæ¯
    if doc_type == "è…³æœ¬":
        core_messages = []
        core_msg_pattern = r'[-â€¢]\s*æ ¸å¿ƒè¨Šæ¯\s*[1234][:ï¼š]\s*(.+)'
        for m in re.finditer(core_msg_pattern, md_text, flags=re.MULTILINE):
            core_messages.append(m.group(1).strip())
        if core_messages:
            fields["core_messages"] = core_messages

    return fields


def main():
    parser = argparse.ArgumentParser(
        description="å°‡ Markdown è½‰æ›ç‚º Word æ–‡ä»¶ä¸¦ç”¢ç”Ÿæ¬„ä½èªªæ˜ JSON",
        epilog="""
ç¯„ä¾‹ï¼š
  python scripts/generate_doc_outputs.py --type è…³æœ¬ outputs/è…³æœ¬/è…³æœ¬.md
  python scripts/generate_doc_outputs.py --type æ¡è¨ªç¨¿ outputs/æ¡è¨ªç¨¿/æ¡è¨ªç¨¿.md --reference reference/å°ˆåˆŠç‰ˆå‹_reference.docx
        """
    )
    parser.add_argument(
        "--type",
        choices=["è…³æœ¬", "æ¡è¨ªç¨¿"],
        required=True,
        help="æŒ‡å®šè¼¸å‡ºé¡å‹ï¼ˆè…³æœ¬ / æ¡è¨ªç¨¿ï¼‰"
    )
    parser.add_argument(
        "src_md",
        help="ä¾†æº Markdown æª”è·¯å¾‘ï¼ˆç”± AI ç”¢å‡ºçš„è…³æœ¬.md æˆ– æ¡è¨ªç¨¿.mdï¼‰"
    )
    parser.add_argument(
        "--out-dir",
        default="outputs",
        help="è¼¸å‡ºæ ¹ç›®éŒ„ï¼Œé è¨­ç‚º ./outputs"
    )
    parser.add_argument(
        "--reference",
        help="reference.docx è·¯å¾‘ï¼ˆé¸å¡«ï¼‰ï¼Œç”¨æ–¼å¥—ç”¨ Word æ¨£å¼"
    )
    args = parser.parse_args()

    # æª¢æŸ¥ä¾†æºæª”æ¡ˆ
    src_path = pathlib.Path(args.src_md).resolve()
    if not src_path.exists():
        print(f"âœ— ä¾†æºæª”ä¸å­˜åœ¨ï¼š{src_path}", file=sys.stderr)
        sys.exit(1)

    # è¨­å®šè¼¸å‡ºç›®éŒ„
    out_root = pathlib.Path(args.out_dir).resolve()
    type_dir = out_root / args.type  # ./outputs/è…³æœ¬ æˆ– ./outputs/æ¡è¨ªç¨¿
    type_dir.mkdir(parents=True, exist_ok=True)

    # æ±ºå®šè¼¸å‡ºæª”å
    if args.type == "è…³æœ¬":
        md_out = type_dir / "è…³æœ¬.md"
        doc_out = type_dir / "è…³æœ¬_templete.docx"
        json_out = type_dir / "è…³æœ¬æ¬„ä½èªªæ˜.json"
    else:
        md_out = type_dir / "æ¡è¨ªç¨¿.md"
        doc_out = type_dir / "æ¡è¨ªç¨¿_templete.docx"
        json_out = type_dir / "æ¡è¨ªç¨¿èªªæ˜.json"

    # è™•ç† reference.docx
    reference_docx = None
    if args.reference:
        reference_docx = pathlib.Path(args.reference).resolve()
        if not reference_docx.exists():
            print(f"âš  è­¦å‘Šï¼šæŒ‡å®šçš„ reference.docx ä¸å­˜åœ¨ï¼š{reference_docx}", file=sys.stderr)
            reference_docx = None

    print(f"\n{'='*60}")
    print(f"docflow - æ–‡ç¨¿è½‰æ›å·¥å…·")
    print(f"{'='*60}")
    print(f"é¡å‹ï¼š{args.type}")
    print(f"ä¾†æºï¼š{src_path}")
    print(f"è¼¸å‡ºç›®éŒ„ï¼š{type_dir}")
    if reference_docx:
        print(f"åƒè€ƒæ¨£å¼ï¼š{reference_docx}")
    print(f"{'='*60}\n")

    # è®€ä¾†æº Markdown
    md_text = src_path.read_text(encoding="utf-8")

    # 1. è¤‡è£½ Markdown åˆ°æ¨™æº–æª”å
    md_out.write_text(md_text, encoding="utf-8")
    print(f"âœ“ Markdownï¼š{md_out}")

    # 2. å‘¼å« pandoc ç”¢å‡º Word
    try:
        md_to_docx(md_out, doc_out, reference_docx)
    except Exception as e:
        print(f"âœ— Word è½‰æ›å¤±æ•—ï¼Œä½†æœƒç¹¼çºŒç”¢ç”Ÿ JSON", file=sys.stderr)

    # 3. ç°¡å–®è§£ææ¬„ä½ï¼Œç”¢å‡º JSON
    fields = extract_fields_from_md(md_text, args.type)
    payload = {
        "type": args.type,
        "source_markdown": str(src_path),
        "generated_markdown": str(md_out),
        "generated_docx": str(doc_out),
        "fields": fields
    }

    json_out.write_text(
        json.dumps(payload, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
    print(f"âœ“ æ¬„ä½èªªæ˜ JSONï¼š{json_out}")

    print(f"\n{'='*60}")
    print(f"âœ“ è½‰æ›å®Œæˆï¼")
    print(f"{'='*60}\n")

    # é¡¯ç¤ºæå–çš„æ¬„ä½æ‘˜è¦
    print("ğŸ“‹ æå–çš„æ¬„ä½æ‘˜è¦ï¼š")
    if "headline" in fields:
        print(f"  ä¸»æ¨™ï¼š{fields['headline'][:50]}...")
    if "subhead" in fields:
        print(f"  çœ‰æ¨™ï¼š{fields['subhead'][:50]}...")
    if "subject_person" in fields:
        print(f"  å—è¨ªè€…ï¼š{fields['subject_person']}")
    if "sections" in fields:
        print(f"  æ®µè½æ•¸ï¼š{len(fields['sections'])}")
        for sec in fields['sections']:
            print(f"    - {sec['number']}ã€€{sec['title']}")
    print()


if __name__ == "__main__":
    main()
